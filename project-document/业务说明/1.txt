POI数据生产大流程
功能模块划分：
    接入模块（接入服务 + 接入任务）：数据接入
    标准化模块（标准化任务 + 区划服务）：字段映射转换数据规格，补充信息（行政区划），含有敏感词数据拦截，
    融合模块 （融合任务 + 聚合服务 + 索引刷新任务）
    分发模块（分发任务）
    统计模块（SQL统计分析）
    人工运营平台：（各阶段数据查询，任务心跳监控，数据人工修复推送，核心数据的生命周期监控）
    内容服务：管理图片，评论信息
    离线挖掘(数据置信度、评分值)

系统功能:
    数据生产日志监控功能;(Flink侧边流 + ELK) [receiving + transform + sending]
    主链路任务心跳检测功能 + 报警邮件发送;
    数据分优先级处理，提供普通流、快速流、紧急流三种通道;
    数据容灾回滚和迁移平台能力;(利用hdfs备份能力，用存档的hdfs文件回滚Hbase、Lemondb、ES表)
    每日全量+实时增量能力;
    数据接入+标准化(提升数据质量)+融合+质检下发(把控数据质量);
    核心数据的生命周期监控(数据处理过程任务反馈拦截还是下发);
    人工运营平台兜底操作;
    模块粒度数据重刷修复能力;
    数据限流能力(flink背压机制+令牌桶);
    动态配置流修改任务核心业务参数(广播流);
    构建离线数仓提供生产指标监控能力(数据生产性能指标(tps、稳定性[自动重启次数]) + 数据质量指标(字段填充率 、 字段变化率、各种类型增长/减少率) +

flink: yarn-per-job模式 (JobManager在集群中,不在客户端上)
spark: cluster模式 (Driver在集群中，不在客户端上)

最开始的平台(Oap):flink（一套环境，有hdfs）与spark集群（另一套环境，有hdfs）分离, 数据存储集群用的是spark的hdfs, 3PB空间

数据规模：
    累计全量：
        海外数据原始接入40亿左右、生产融合后合格数据11亿；(5TB)
        国内数据原始接入3亿左右、生产融合后合格数据8kw; (800GB)
    实时增量：
        限速5W/h，120W/h下发下游, 8000kw
单线程50条/s

优化：
    代码性能优化:
        Hive数仓：

    业务逻辑优化:
       日志瘦身（每个任务，一条数据基本有3条日志，接入，转换，发送，日志中展示数据只在终止步骤展示，其它步骤，只展示数据基本信息）